{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import uuid\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"chromadb\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger().setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# mongo db connection\n",
    "\n",
    "try:\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[\"assistant_db\"]\n",
    "    users_collection = db[\"users\"]\n",
    "    chats_collection = db[\"chats\"]\n",
    "    print(\"Connected to MongoDB!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"MongoDB Connection Failed: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model & chroma db\n",
    "\n",
    "client_chroma = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "db_chroma = client_chroma.get_or_create_collection(\"chat_context\")\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load mistral 7b\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    \"models/\",\n",
    "    model_file = \"mistral-7b-instruct-v0.2.Q5_K_M.gguf\",\n",
    "    model_type = \"mistral\",\n",
    "    gpu_layers = 25,\n",
    "    temperature = 0.1,\n",
    "    top_k = 30,\n",
    "    top_p = 0.85,\n",
    "    max_new_tokens = 250,\n",
    "    stream = False,\n",
    "    seed = 42,\n",
    "    context_length = 4096,\n",
    ")\n",
    "\n",
    "print(\"\\nModel loaded successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ User found! Loading profile...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_id = None\n",
    "\n",
    "def get_or_create_user():\n",
    "    global user_id\n",
    "    username = input(\"Enter your username: \").strip()\n",
    "\n",
    "    user = users_collection.find_one({\"username\": username})\n",
    "\n",
    "    if user:\n",
    "        print(\"üîπ User found! Loading profile...\\n\")\n",
    "        user_id = user[\"_id\"]\n",
    "    else:\n",
    "        print(\"üîπ New user detected! Let's create your profile.\\n\")\n",
    "        user_data = {\n",
    "            \"_id\": str(uuid.uuid4()),\n",
    "            \"username\": username,\n",
    "            \"age\": int(input(\"Enter your age: \")),\n",
    "            \"gender\": input(\"Identify yourself as [Male, Female, Others]: \").strip(),\n",
    "            \"location\": input(\"Where are you from: \").strip(),\n",
    "            \"mother-tongue\": input(\"Your mother tongue: \").strip(),\n",
    "            \"bio\": input(\"Enter a short bio: \").strip(),\n",
    "            \"interests\": input(\"Enter your interests (comma-separated): \").split(\",\"),\n",
    "            \"preferred_topics\": input(\"Topics you wish to explore [tech, health, stocks]: \").strip(),\n",
    "        }\n",
    "        user_id = user_data[\"_id\"]\n",
    "        users_collection.insert_one(user_data)\n",
    "        print(\"Profile created successfully!\\n\")\n",
    "\n",
    "get_or_create_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_chat_in_chroma(query, response, context):\n",
    "    try:\n",
    "        chat_id = str(uuid.uuid4())\n",
    "        \n",
    "        existing_ids = db_chroma.get(ids=[chat_id])\n",
    "        if existing_ids and len(existing_ids[\"documents\"]) > 0:\n",
    "            return \n",
    "\n",
    "        response_vector = sentence_model.encode([response])[0]\n",
    "        context_vector = sentence_model.encode([context])[0]\n",
    "\n",
    "        db_chroma.add(\n",
    "            ids=[chat_id],\n",
    "            embeddings=[response_vector],\n",
    "            documents=[response],\n",
    "            metadatas=[{\"context\": context}],\n",
    "        )\n",
    "        \n",
    "        db_chroma.add(\n",
    "            ids=[chat_id],\n",
    "            embeddings=[context_vector],\n",
    "            documents=[context],\n",
    "            metadatas=[{\"context\": context}],\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save chat in ChromaDB: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context_from_chroma(query, top_k = 4):\n",
    "    \"\"\"Retrieve the most relevant context from ChromaDB\"\"\"\n",
    "    query_vector = sentence_model.encode([query])[0]\n",
    "    results = db_chroma.query(query_embeddings=[query_vector], n_results=top_k)\n",
    "    \n",
    "    context = \"\"\n",
    "\n",
    "    for result in results['documents']:\n",
    "        context += \" \".join(result) + \"\\n\" if isinstance(result, list) else result + \"\\n\"\n",
    "    \n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what are my upcoming meetings\n",
      "\n",
      "Predicted Contexts:\n",
      "\n",
      "Assistant:     You have meetings coming up with Samantha Wheeler on the 8th of April at 4pm, and with Josh on the 6th of April at RSET.\n",
      "\n",
      "ü§ñ Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"query: \").strip()\n",
    "\n",
    "    if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"ü§ñ Goodbye!\")\n",
    "        break\n",
    "\n",
    "    print(f\"User: {query}\\n\")\n",
    "\n",
    "    user_data = users_collection.find_one({\"_id\": user_id})\n",
    "\n",
    "    if not user_data:\n",
    "        print(\"‚ùå User profile not found. Proceeding without context.\")\n",
    "        user_context = \"No additional user information available.\"\n",
    "    else:\n",
    "        user_context = (\n",
    "            f\"User Name: {user_data.get('full_name', 'No full name available')}, \"\n",
    "            f\"User Age: {user_data.get('age', 'No age available')}, \"\n",
    "            f\"User Gender: {user_data.get('gender', 'No gender available')}, \"\n",
    "            f\"User Location: {user_data.get('location', 'No location available')}, \"\n",
    "            f\"User Bio: {user_data.get('bio', 'No bio available')}, \"\n",
    "            f\"Interests: {', '.join(user_data.get('interests', []))}, \"\n",
    "            f\"Preferred Topics: {', '.join(user_data.get('preferred_topics', []))}, \"\n",
    "            f\"Favorite Books: {', '.join(user_data.get('favorite_books', []))}, \"\n",
    "            f\"Favorite Movies: {', '.join(user_data.get('favorite_movies', []))}, \"\n",
    "            f\"Occupation: {user_data.get('occupation', 'Unknown')}, \"\n",
    "            f\"Skills: {', '.join(user_data.get('skills', []))}, \"\n",
    "            f\"Learning Goals: {', '.join(user_data.get('learning_goals', []))}, \"\n",
    "            f\"Timezone: {user_data.get('timezone', 'Unknown')}, \"\n",
    "            f\"Preferred Response Tone: {user_data.get('preferred_response_tone', 'Neutral')}.\"\n",
    "        )\n",
    "\n",
    "    previous_context = retrieve_context_from_chroma(query)\n",
    "    full_context = f\"{user_context}\\nPrevious Context:\\n{previous_context}\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    User: {query}\\n\n",
    "    Instruction: Only answer to the question, nothing extra. Only provide information if you have access to factual data, if you don't have the information, please say so explicitly.\\n\n",
    "    Context: {full_context}\\n\n",
    "    Assistant (Concise & Professional):\n",
    "\"\"\"\n",
    "    response = llm(prompt)\n",
    "\n",
    "    print(f\"Assistant: {response}\\n\")\n",
    "    \n",
    "    # store chat inside of mongodb\n",
    "    try:\n",
    "        chat_data = {\n",
    "            \"user_id\": user_id,\n",
    "            \"query\": query,\n",
    "            \"response\": response,\n",
    "            \"context\": full_context,\n",
    "            \"timestamp\": datetime.datetime.now(datetime.UTC)\n",
    "        }\n",
    "        chats_collection.insert_one(chat_data)\n",
    "\n",
    "\n",
    "        store_chat_in_chroma(query, response, full_context)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save chat: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
